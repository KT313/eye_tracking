{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "113b0d21-db4a-4bf6-8fbd-0796ece6bb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3942ec7f-a239-4668-ba54-7a470677a570",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tobi/.local/lib/python3.10/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "from lib.imports import *\n",
    "from lib.video_processor import VideoProcessor\n",
    "from lib.misc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ebc0bec-6355-4fa8-b7c1-a647143d627f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sudo modprobe v4l2loopback\n",
    "# sudo modprobe v4l2loopback devices=1 card_label=\"Virtual Camera\" exclusive_caps=1\n",
    "# sudo modprobe -r v4l2loopback && sudo modprobe v4l2loopback devices=1 video_nr=4 card_label=\"Virtual\" exclusive_caps=1 max_buffers=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e42670c-0193-4a77-82f2-2c6b7dadf5fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.9 üöÄ Python-3.10.12 torch-2.2.1+cu121 CPU (11th Gen Intel Core(TM) i7-1165G7 2.80GHz)\n",
      "WARNING ‚ö†Ô∏è half=True only compatible with GPU export, i.e. use device=0\n",
      "YOLOv8n-pose summary (fused): 187 layers, 3154073 parameters, 0 gradients, 8.6 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'models/eyes_128_auto.pt' with input shape (3, 3, 128, 128) BCHW and output shape(s) (3, 35, 336) (6.2 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.14.1 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m simplifying with onnxsim 0.4.36...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success ‚úÖ 0.7s, saved as 'models/eyes_128_auto.onnx' (12.1 MB)\n",
      "\n",
      "Export complete (2.1s)\n",
      "Results saved to \u001b[1m/home/tobi/Desktop/eye_tracking/models\u001b[0m\n",
      "Predict:         yolo predict task=pose model=models/eyes_128_auto.onnx imgsz=128  \n",
      "Validate:        yolo val task=pose model=models/eyes_128_auto.onnx imgsz=128 data=data/yolo_pose_dataset.yaml  \n",
      "Visualize:       https://netron.app\n",
      "Loading models/yolov8n-face-lindevs.onnx for ONNX Runtime inference...\n",
      "Loading models/eyes_128_auto.onnx for ONNX Runtime inference...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing video of shape (1798, 720, 1280, 3) to path outputs/youtube_vid_04.mp4 with frame_rate 29.97002997002997, should be 59.99326666666667 seconds long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                            | 475/1798 [00:02<00:07, 181.70it/s]"
     ]
    }
   ],
   "source": [
    "interpolate_rate=2\n",
    "eyes_int_rate=0\n",
    "eye_model_size=128\n",
    "input_source = \"example_video/youtube_vid_04.mp4\" # 0 # \"example_video/example_vid_original.mp4\"\n",
    "form=\"onnx\"\n",
    "\n",
    "\n",
    "eye_batch_rate=(interpolate_rate//(eyes_int_rate+1))+1\n",
    "convert_pt_to_onnx(model_path=f'models/eyes_{eye_model_size}_auto.pt', imgsz=eye_model_size, batch=eye_batch_rate, form=form)\n",
    "\n",
    "processor = VideoProcessor(eye_model_size=eye_model_size, form=form)\n",
    "out = processor.start(video_path=input_source, \n",
    "                      interpolate_rate=interpolate_rate, \n",
    "                      eyes_int_rate=eyes_int_rate, \n",
    "                      eye_batch_rate=eye_batch_rate, \n",
    "                      return_instead=False, \n",
    "                      disable_stats=False, \n",
    "                      save_output=True, \n",
    "                      file_process_fast=False,\n",
    "                      make_virtual_cam=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23da502-c30f-43bc-8d2e-1d1682709209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write_video(out, \"example_video/flexpressions_cropped.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403489e0-3925-4614-a38f-cadbbf3d9a38",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1875eb63-d894-47ce-809b-a3a466606694",
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_video_annotations_for_training(val_ratio=0.1, multiply_train_data=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebc9d85-ed80-4d29-970c-98df08e77342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you don't want to track training with comet don't run this cell and set usecomet=False in the next cell\n",
    "init_comet(api_key=\"your_api_key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6dd4300-4a05-4608-914e-ceb6382ec721",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for image_size in [128, 256, 64, 512]: # might get stuck before starting 2nd batch, if this happens just restart this cell\n",
    "    train_model(pretrained_model='models/yolov8n-pose.pt', save_name=f\"training_{image_size}_autotrain\", imgsz=image_size, epochs=100, batch=256, amp=True, workspace=\"comet_workspacename\", usecomet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697fc3cb-c75b-4a4e-8794-0dd472cb7c25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
